{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking:\n",
    "### Objective: Systematically test prompts, GPT models, and other techniques for D&D AI use cases\n",
    "\n",
    "### Description: \n",
    "* There are 6 simple scenarios that two chracters might have dialogue in. \n",
    "* 3 prior messages are defined to create each scenario. \n",
    "* The chatbot will respond 1 or more times, alternating the character it is roleplaying.\n",
    "\n",
    "Related files: \n",
    "* bm1.py -- runs benchmark\n",
    "* dialogue_basic.json -- defines scenarios\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def display_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        output = json.load(f, )\n",
    "    print(json.dumps(output, indent=4))\n",
    "\n",
    "display_json('../scenarios/dialogue-basic.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark 1: Simple Dialogue Part 1 -- Single Response\n",
    "\n",
    "Why? \n",
    "* Chatbots should be able to respond to dialogue with dialogue in-character and in a clear and error-free manner.\n",
    "\n",
    "Challenges:\n",
    "1. All answers should address the previous message.\n",
    "2. All answers should be dialogue, with no extra text.\n",
    "3. Remove all NER errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1\n",
    "Notes: Issues with challenge *1* and *3*: NER and responding to the correct prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './../mlruns/834045129700860192/9a69d75c91674318adc509b9fd0b06c3/artifacts/bm1_mr1.json'\n",
    "display_json(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2\n",
    "\n",
    "Let's try to improve NER by injecting names into the qa_system_prompt:\n",
    "\n",
    "qa_system_prompt: \n",
    "\"...You are roleplaying as {responder_name}, and you are responding to {prompter_name}....\n",
    "\n",
    "Notes: Passes all challenges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './../mlruns/834045129700860192/6d5d4d5f3de94309b51541b6f751b35c/artifacts/bm1_mr1.json'\n",
    "display_json(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Benchmark 1: Simple Dialogue Part 2 -- Multiple Responses (k=4)\n",
    "\n",
    "Why? \n",
    "* To verify challenges from part 1 at a larger scale\n",
    "* To test conversational progression and ensure conversations don't get \"stuck\"\n",
    "\n",
    "Challenges:\n",
    "1. All answers should address the previous message.\n",
    "2. All answers should be dialogue, with no extra text.\n",
    "3. Remove all NER errors.\n",
    "4. There should be clear conversational progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 -- no changes\n",
    "\n",
    "Notes: \n",
    "* Responses to 3 scenarios include 3rd person narration. (Fails 2)\n",
    "* Clear conversational progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './../mlruns/946018013973686521/b3dfd936a6784bf28b537d9bfc8aafdf/artifacts/bm1_mr4.json'\n",
    "display_json(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2 -- Directly specify to use only dialogue in response\n",
    "\n",
    " 'qa_system_prompt': 'You are a role playing chatbot for a Dungeons and Dragons game. Use the retrieved context to answer the prompt. If the context does not apply, respond in a way that makes sense. Use three sentences maximum, and keep the answer concise. You are roleplaying as {responder_name}, and you are responding to {prompter_name}. Use only dialogue in your response.\\n\\n CONTEXT: {context}',\n",
    "\n",
    "Notes: \n",
    "* All scenarios contain only dialogue. (Passes 2)\n",
    "* Clear conversational progression.\n",
    "* Passes all challenges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './../mlruns/946018013973686521/ba90cb1dccc844cf88a06c70f10c3e1d/artifacts/bm1_mr4.json'\n",
    "display_json(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways and Next Steps\n",
    "\n",
    "### Takeaways\n",
    "1. Simple Dialogue is consistent and passes challenges with single and multiple (4) responses on all scenarios.\n",
    "2. Direct instructions work best for constraining behavior. (Don't make the bot guess behavior!)\n",
    "\n",
    "### Next Steps\n",
    "1. Implement a tags-based prompt template, which appends instructions based on tags. For example, a bot with the tag \"dialogue-only\" should have the sentence \"Use only dialogue in your response.\"\n",
    "2. Implement an action benchmark for action-only and action-dialogue scenarios.\n",
    "3. Implement an agentic benchmark for agentic chatbot behavior, deciding when an action or dialogue is appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
